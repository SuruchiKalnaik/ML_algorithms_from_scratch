{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "from random import randrange\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LogisticRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "        self.epochs = 1000\n",
    "        self.alpha = 0.001\n",
    "        self.parameters = []\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        self.x_minmax = []\n",
    "        self.y_minmax = []\n",
    "        \n",
    "    def min_max(self):\n",
    "        \n",
    "        for i in range(len(self.X[0])):\n",
    "            col_val = [j[i] for j in self.X]\n",
    "            min_value = min(col_val)\n",
    "            max_value = max(col_val)\n",
    "            self.x_minmax.append([min_value, max_value])\n",
    "        \n",
    "        y_min_value = min(self.y)\n",
    "        y_max_value = max(self.y)\n",
    "        self.y_minmax.append([y_min_value,y_max_value])\n",
    "        \n",
    "    \n",
    "    def normalization(self):\n",
    "        \n",
    "        for i in range(len(self.X)):\n",
    "            for j in range(len(self.X[0])):\n",
    "                numerator = self.X[i][j] - self.x_minmax[j][0]\n",
    "                denominator = self.x_minmax[j][1] - self.x_minmax[j][0]\n",
    "                self.X[i][j] = numerator/denominator\n",
    "            \n",
    "            numerator = self.y[i] - self.y_minmax[0][0]\n",
    "            denominator = self.y_minmax[0][1] - self.y_minmax[0][0]\n",
    "            self.y[i] = numerator/denominator\n",
    "    \n",
    "    \n",
    "    # Evaluate an algorithm using a train/test split\n",
    "    def train_test_split(self,X, y, split):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.y = self.y.astype(float)\n",
    "        self.min_max()\n",
    "        self.normalization()\n",
    "        \n",
    "        X_train = list()\n",
    "        y_train = list()\n",
    "        train_size = split * len(X)\n",
    "        X_test = list(self.X)\n",
    "        y_test = list(self.y)\n",
    "        \n",
    "        while len(X_train) < train_size:\n",
    "            index = randrange(len(X_test))\n",
    "            X_train.append(X_test.pop(index))\n",
    "            y_train.append(y_test.pop(index))\n",
    "        \n",
    "        return X_train,X_test,y_train,y_test\n",
    "    \n",
    "    \n",
    "    def accuracy_check(self, pred, actual):\n",
    "        correct = 0\n",
    "        \n",
    "        for i in range(len(actual)):\n",
    "            if(pred[i] == actual[i]):\n",
    "                correct = correct + 1\n",
    "        \n",
    "        accuracy = (correct/len(actual))\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def score(self,X_test,y_test):\n",
    "        predictions = []\n",
    "        unique_value = np.unique(y_test)\n",
    "        \n",
    "        for i in X_test:\n",
    "            value_difference = []\n",
    "            pred = self.prediction(i,self.parameters)\n",
    "            for j in unique_value:\n",
    "                value_difference.append(abs(j-pred))\n",
    "            for j in range(len(value_difference)):\n",
    "                if value_difference[j] == min(value_difference):\n",
    "                    predictions.append(unique_value[j])\n",
    "        \n",
    "        accuracy = self.accuracy_check(predictions,y_test)\n",
    "        return \"{:.2f}\".format(float(accuracy))\n",
    "\n",
    "    \n",
    "    def prediction(self, row, parameters):\n",
    "        hypothesis = parameters[0]\n",
    "        \n",
    "        for i in range(len(row)):\n",
    "            hypothesis = hypothesis + row[i]*parameters[i+1]\n",
    "        \n",
    "        return 1/(1+exp(-hypothesis))\n",
    "    \n",
    "    \n",
    "    def cost_function(self, parameters):\n",
    "        cost = 0\n",
    "        \n",
    "        for i in range(len(self.X_train)):\n",
    "            pred = self.prediction(self.X_train[i], parameters)\n",
    "            y = self.y_train[i]\n",
    "            cost = cost + (-(y*np.log(pred)) + (-(1-y)*np.log(1-pred)))\n",
    "        average_cost = cost/len(self.X_train)\n",
    "        \n",
    "        return average_cost\n",
    "    \n",
    "    \n",
    "    def gradient_descent(self):\n",
    "        parameters = [0] * (len(self.X_train[0])+1)\n",
    "        cost_history = []\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            for j in range(len(self.X_train)):\n",
    "                pred = self.prediction(self.X_train[j],parameters)\n",
    "                parameters[0] = parameters[0] - self.alpha*(pred - self.y_train[j])\n",
    "                for k in range(len(self.X_train[j])):\n",
    "                    parameters[k+1] = parameters[k+1] - self.alpha*(pred-self.y_train[j])*self.X_train[j][k]\n",
    "            cost_history.append(self.cost_function(parameters))\n",
    "        \n",
    "        return cost_history,parameters\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        cost_history,parameters = self.gradient_descent()\n",
    "        self.parameters = parameters\n",
    "        \n",
    "        \n",
    "    def predict(self,row):\n",
    "        value_difference = []\n",
    "        \n",
    "        for j in range(len(row)):\n",
    "            numerator = row[j] - self.x_minmax[j][0]\n",
    "            denominator = self.x_minmax[j][1] - self.x_minmax[j][0]\n",
    "            row[j] = numerator/denominator\n",
    "        \n",
    "        value = self.prediction(row,self.parameters)\n",
    "        unique_value = np.unique(self.y)\n",
    "        \n",
    "        for j in unique_value:\n",
    "            value_difference.append(abs(j-value))\n",
    "        \n",
    "        for j in range(len(value_difference)):\n",
    "            if value_difference[j] == min(value_difference):\n",
    "                value = unique_value[j]\n",
    "\n",
    "        denominator = self.y_minmax[0][1] - self.y_minmax[0][0]\n",
    "        value = (value * denominator) + self.y_minmax[0][0]\n",
    "        \n",
    "        return int(value)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    from sklearn.datasets import load_iris\n",
    "    iris = load_iris()\n",
    "    X = iris.data\n",
    "    y = iris.target\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    X_train,X_test,y_train,y_test  = model.train_test_split(X, y, .8)\n",
    "    model.fit(X_train,y_train)\n",
    "    print(model.score(X_test,y_test))\n",
    "    print(model.predict([5.2, 4.1, 1.5, 0.1]))\n",
    "    print(model.predict([6.4, 3.2, 4.5, 1.5]))\n",
    "    print(model.predict([6.2, 3.4, 5.4, 2.3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
